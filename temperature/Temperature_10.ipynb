{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Temperature_10.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwJzQrr6u_s9","outputId":"46f2e681-599f-4aed-db71-0d2481a2fb99"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RCL8vmU8vOf_","outputId":"2e24ae03-9560-4a47-fe1a-099303f8f4e5"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1nQN1RamvUkt"},"source":["import os\n","import cv2\n","from PIL import Image\n","import numpy as np\n","import scipy\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","plt.style.use('seaborn')\n","\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from tqdm import tqdm\n","\n","import time\n","import timeit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5LafAravWx_"},"source":["import keras\n","import tensorflow as tf\n","from keras import layers\n","from keras.models import Model\n","from keras.layers import Lambda, concatenate\n","from tensorflow.keras.utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import GlobalAveragePooling2D , Conv2D , MaxPooling2D\n","from keras.layers import  Dropout , BatchNormalization , Dense\n","from keras.optimizers import Adam\n","from tensorflow.keras.applications import ResNet50\n","from keras.callbacks import Callback , ReduceLROnPlateau , ModelCheckpoint\n","from sklearn.metrics import cohen_kappa_score, accuracy_score\n","from keras.losses import categorical_crossentropy as logloss\n","from keras.metrics import categorical_accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygz1SKZKvYwR","outputId":"9c8911d1-5124-43f9-bf71-300269ea931e"},"source":["benign_train = np.load('/content/drive/MyDrive/CSE465/Dataset/benign_train.npy')\n","malign_train = np.load('/content/drive/MyDrive/CSE465/Dataset/malign_train.npy')\n","benign_test = np.load('/content/drive/MyDrive/CSE465/Dataset/benign_test.npy')\n","malign_test = np.load('/content/drive/MyDrive/CSE465/Dataset/malign_test.npy')\n","print('Done Loaded :)')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Done Loaded :)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLjanYKivaqF","outputId":"971357ad-944b-416a-832c-bb28e9749c6b"},"source":["# Shape of our dataset\n","print(f'Benign Train:',benign_train.shape)\n","print(f'Malignant Train',malign_train.shape)\n","print(f'Benign Test:',benign_test.shape)\n","print(f'Malignant Test',malign_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Benign Train: (3500, 224, 224, 3)\n","Malignant Train (3496, 224, 224, 3)\n","Benign Test: (1500, 224, 224, 3)\n","Malignant Test (1500, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5DNk8wRPZgFl"},"source":["**Set to class 0 and class 1**"]},{"cell_type":"code","metadata":{"id":"IY14E6WpvjuZ"},"source":["benign_train_label = np.zeros(len(benign_train),dtype=float)\n","malign_train_label = np.ones(len(malign_train),dtype=float)\n","benign_test_label = np.zeros(len(benign_test),dtype=float)\n","malign_test_label = np.ones(len(malign_test),dtype=float) \n","\n","X_train = np.concatenate((benign_train, malign_train), axis = 0)\n","Y_train = np.concatenate((benign_train_label, malign_train_label), axis = 0)\n","X_test = np.concatenate((benign_test, malign_test), axis = 0)\n","Y_test = np.concatenate((benign_test_label, malign_test_label), axis = 0)\n","\n","s = np.arange(X_train.shape[0])\n","np.random.shuffle(s)\n","X_train = X_train[s]\n","Y_train = Y_train[s]\n","\n","s = np.arange(X_test.shape[0])\n","np.random.shuffle(s)\n","X_test = X_test[s]\n","Y_test = Y_test[s]\n","\n","Y_train = to_categorical(Y_train, num_classes= 2)\n","Y_test = to_categorical(Y_test, num_classes= 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HMPa7P1XfuuN","outputId":"36fea5a1-d9ae-4d01-b7bb-3c0598cfb58a"},"source":["print(f'X train shape:',X_train.shape)\n","print(f'X test shape:',X_test.shape)\n","print(f'Y train shape:',Y_train.shape)\n","print(f'Y test shape:',Y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["X train shape: (6996, 224, 224, 3)\n","X test shape: (3000, 224, 224, 3)\n","Y train shape: (6996, 2)\n","Y test shape: (3000, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"18-dtZkWZfTc"},"source":["**Split**"]},{"cell_type":"code","metadata":{"id":"ZUpq1QB1vl-j"},"source":["x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyL-RqBfvnfm","outputId":"6169bfd0-8eb7-4dcd-ea28-6240099e75cc"},"source":["print(f'x train shape:',x_train.shape)\n","print(f'x val shape:',x_val.shape)\n","print(f'y train shape:',y_train.shape)\n","print(f'y val shape:',y_val.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x train shape: (5596, 224, 224, 3)\n","x val shape: (1400, 224, 224, 3)\n","y train shape: (5596, 2)\n","y val shape: (1400, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3O5-mfAvpmL","outputId":"456ecaf3-0f29-4cc1-a54b-88e9463f2a22"},"source":["# Teacher model with ResNet50\n","def build_model(backbone , lr = 1e-4):\n","  model = Sequential()\n","  model.add(backbone)\n","  model.add(layers.GlobalAveragePooling2D())\n","  model.add(layers.Dropout(0.5))\n","  model.add(layers.BatchNormalization())\n","  model.add(layers.Dense(2 , activation='softmax'))\n","  \n","  model.compile(\n","        loss='categorical_crossentropy',\n","        optimizer=Adam(learning_rate=1e-4),\n","        metrics=['accuracy']\n","    )\n","    \n","  return model\n","\n","resnet = ResNet50(\n","    weights = 'imagenet',\n","    include_top = False,\n","    input_shape = (224 , 224 , 3)\n",")\n","# call the model \n","model = build_model(resnet , lr = 1e-4)\n","model.build((None, 224, 224, 3))\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","module_wrapper_2 (ModuleWrap (None, 7, 7, 2048)        23587712  \n","_________________________________________________________________\n","global_average_pooling2d_2 ( (None, 2048)              0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 2048)              8192      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 4098      \n","=================================================================\n","Total params: 23,600,002\n","Trainable params: 23,542,786\n","Non-trainable params: 57,216\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_NzK9jN7i6yP"},"source":["learn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,verbose=1,factor=0.2, min_lr=1e-4)\n","filepath=\"ResNet50weights.best.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVroJarTwWl6","outputId":"a4e3cf85-6f56-428a-ce69-3422b82a36a1"},"source":["# Training the teacher model with Resnet50\n","# Train the teacher model as usual\n","# Configuration\n","import time\n","epochs = 10 \n","batch_size = 64\n","\n","# Calculate the starting time    \n","start_time = time.time()\n","\n","teacher_his = model.fit(x_train, y_train,\n","            batch_size=batch_size,\n","            epochs=epochs,\n","            verbose=1,\n","            validation_data=(x_val, y_val),\n","            callbacks=[learn_control, checkpoint])\n","\n","\n","end_time = time.time()\n","print(\"--- Time taken to train : %s seconds ---\" % ((end_time - start_time)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","88/88 [==============================] - 61s 637ms/step - loss: 0.3081 - accuracy: 0.8843 - val_loss: 0.2629 - val_accuracy: 0.8729\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 2/10\n","88/88 [==============================] - 57s 643ms/step - loss: 0.0644 - accuracy: 0.9741 - val_loss: 0.1101 - val_accuracy: 0.9650\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 3/10\n","88/88 [==============================] - 58s 655ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.1530 - val_accuracy: 0.9393\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 4/10\n","88/88 [==============================] - 58s 663ms/step - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.1766 - val_accuracy: 0.9593\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 5/10\n","88/88 [==============================] - 58s 663ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.1599 - val_accuracy: 0.9543\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 6/10\n","88/88 [==============================] - 58s 665ms/step - loss: 0.0454 - accuracy: 0.9843 - val_loss: 0.1656 - val_accuracy: 0.9443\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 7/10\n","88/88 [==============================] - 58s 665ms/step - loss: 0.0139 - accuracy: 0.9945 - val_loss: 0.1658 - val_accuracy: 0.9571\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 8/10\n","88/88 [==============================] - 58s 664ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.1792 - val_accuracy: 0.9593\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 9/10\n","88/88 [==============================] - 59s 675ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1863 - val_accuracy: 0.9621\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 10/10\n","88/88 [==============================] - 58s 665ms/step - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.3269 - val_accuracy: 0.9536\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","--- Time taken to train : 627.1994976997375 seconds ---\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWGepXgSjynR","outputId":"9102ca51-57f6-4d1e-a1a7-63be44acf7c7"},"source":["model.save_weights(\"ResNet50_model.h5\") #using h5 extension\n","print(\"model saved!!!\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["model saved!!!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9C50c_0zzjJ","outputId":"ee67d214-c61a-441e-bbd6-22fee4610072"},"source":["Y_val_pred = model.predict(x_val)\n","print(f'The Teacher model Accuracy on the Validation Set:',accuracy_score(np.argmax(y_val, axis=1), np.argmax(Y_val_pred, axis=1)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The Teacher model Accuracy on the Validation Set: 0.9535714285714286\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ybwvuF9z0Nf","outputId":"9c546ea6-ce30-4710-b4eb-afcddfe2fc00"},"source":["#Now let's check my Y_test values\n","print(f'My Y_test values are:\\n' ,Y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["My Y_test values are:\n"," [[1. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," ...\n"," [1. 0.]\n"," [0. 1.]\n"," [1. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xc8YoU-Hz6D3","outputId":"9c90ac9c-97b7-4810-c427-f2e8ef5026db"},"source":["#Now let's check my predcited values from X_test dataset\t\n","# And calculate the y_pred with time\n","import timeit\n","\n","start = timeit.default_timer()\n","#Your statements here\n","y_pred = model.predict(X_test)\n","print(f'My predicted Y_test values are:\\n' ,y_pred)\n","\n","stop = timeit.default_timer()\n","print('\\nTime: ',stop - start,'sec')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["My predicted Y_test values are:\n"," [[9.9991727e-01 8.2722137e-05]\n"," [2.0833357e-12 1.0000000e+00]\n"," [9.9999917e-01 8.7726909e-07]\n"," ...\n"," [9.9992621e-01 7.3832161e-05]\n"," [7.8759923e-09 1.0000000e+00]\n"," [9.9999154e-01 8.4888525e-06]]\n","\n","Time:  8.099131862999911 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDvD1tKvmzup","outputId":"f6e4909e-6753-4937-fda7-866857567a93"},"source":["start = timeit.default_timer()\n","#Your statements here\n","\n","#Now let's check the accuracy between the original & predicted (Y_test , y_pred)\n","print(f'My accuracy on Teacher model with ResNet50 on the Test set is:',accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1)))\n","\n","stop = timeit.default_timer()\n","print('\\nTime: ',stop - start,'sec')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["My accuracy on Teacher model with ResNet50 on the Test set is: 0.991\n","\n","Time:  0.0009553229997436574 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wy97eTzunYLp","outputId":"ff6c071d-53df-479f-8be2-662cac062a23"},"source":["# Classification_report\n","print(f'Classification Report of Resnet50:\\n',classification_report(np.argmax(Y_test, axis=1), np.argmax(y_pred, axis=1)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classification Report of Resnet50:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99      1500\n","           1       0.98      1.00      0.99      1500\n","\n","    accuracy                           0.99      3000\n","   macro avg       0.99      0.99      0.99      3000\n","weighted avg       0.99      0.99      0.99      3000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gedmLVmMrsWF"},"source":["# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n","\n","from sklearn.metrics import roc_curve, auc\n","from numpy import interp\n","from itertools import cycle\n","\n","num_of_classes = y_train.shape[1]\n","print(f'Auc Curve on Validation:\\n')\n","\n","\n","# Compute ROC curve and ROC area for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","for i in range(num_of_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_val[:, i], Y_val_pred[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_val.ravel(), Y_val_pred.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","\n","lw = 3\n","# Plot all ROC curves\n","\n","colors = cycle(['blue', 'orange', 'cornflowerblue'])\n","for i, color in zip(range(num_of_classes), colors):\n","    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n","             label='ROC curve of class {0} (area = {1:0.2f})'\n","             ''.format(i, roc_auc[i]))\n","    \n","plt.style.use('ggplot')\n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Some extension of Receiver operating characteristic to multi-class')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrqGDS-WpM0c"},"source":["# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n","\n","from sklearn.metrics import roc_curve, auc\n","from numpy import interp\n","from itertools import cycle\n","\n","num_of_classes = y_train.shape[1]\n","print(f'Auc Curve on Test set:\\n')\n","\n","\n","# Compute ROC curve and ROC area for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","for i in range(num_of_classes):\n","    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_pred[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), y_pred.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","\n","lw = 3\n","# Plot all ROC curves\n","\n","colors = cycle(['blue', 'orange', 'cornflowerblue'])\n","for i, color in zip(range(num_of_classes), colors):\n","    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n","             label='ROC curve of class {0} (area = {1:0.2f})'\n","             ''.format(i, roc_auc[i]))\n","    \n","plt.style.use('ggplot')\n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Some extension of Receiver operating characteristic to multi-class')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W1EPv8aFnYos"},"source":["**Student Model**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgVqzo_jvs9x","outputId":"d2177d8b-3730-46d2-c0c6-a43eda6fb913"},"source":["# Define the student model\n","# Student model that is stand-alone. We will evaluate its accuracy compared to a teacher trained student model\n","# Hyperparameters\n","input_shape = (224, 224, 3) # Input shape of each image\n","nb_classes = 2 \n","\n","customstudent = Sequential()\n","customstudent.add(Conv2D(128, kernel_size=(3, 3),activation='relu', input_shape=input_shape))\n","customstudent.add(MaxPooling2D(pool_size=(2, 2)))\n","customstudent.add(Conv2D(64, (3, 3), activation='relu'))\n","customstudent.add(MaxPooling2D(pool_size=(2, 2)))\n","customstudent.add(Conv2D(32, (3, 3), activation='relu'))\n","customstudent.add(Dropout(0.25)) # For reguralization\n","\n","customstudent.add(layers.Flatten())\n","\n","customstudent.add(layers.Dense(nb_classes))\n","customstudent.add(layers.Activation('softmax')) # Note that we add a normal softmax layer to begin with\n","\n","\n","customstudent.compile(loss='categorical_crossentropy',\n","              optimizer='adadelta',\n","              metrics=['accuracy'])\n","\n","print(customstudent.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 222, 222, 128)     3584      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 111, 111, 128)     0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 109, 109, 64)      73792     \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 52, 52, 32)        18464     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 52, 52, 32)        0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 86528)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 2)                 173058    \n","_________________________________________________________________\n","activation (Activation)      (None, 2)                 0         \n","=================================================================\n","Total params: 268,898\n","Trainable params: 268,898\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uH990HN_0Ovn"},"source":["# Define a new model that outputs only teacher logits\n","# Raise the temperature of teacher model and gather the soft targets\n","\n","# Collect the logits from the previous layer output and store it in a different model\n","teacher_WO_Softmax = Model(model.input, model.get_layer('dense_2').output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jKo9WI4Y0WWh"},"source":["# Define a manual softmax function\n","def softmax(x):\n","    return np.exp(x)/(np.exp(x).sum())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2xVEZmwE8Gy1"},"source":["# Temperature = 10"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0xHXnJD0YXu","outputId":"ea34e351-6318-4889-826c-55d0a46957dd"},"source":["# Prepare the soft targets and the target data for student to be trained upon\n","# From our temperature experiment we get temp = 10 is gave is best results\n","temp = 10\n","# This model directly gives the logits ( see the teacher_WO_softmax model above)\n","teacher_train_logits = teacher_WO_Softmax.predict(x_train)\n","teacher_test_logits = teacher_WO_Softmax.predict(x_val) \n","\n","# Perform a manual softmax at raised temperature\n","train_logits_T = teacher_train_logits/ temp # temp = 10\n","test_logits_T = teacher_test_logits / temp \n","\n","Y_train_soft = softmax(train_logits_T)\n","Y_test_soft = softmax(test_logits_T)\n","\n","# Concatenate \n","Y_train_new = np.concatenate([y_train, Y_train_soft], axis=1)\n","Y_test_new =  np.concatenate([y_val, Y_test_soft], axis =1)\n","\n","#Print the Shape \n","print(train_logits_T.shape)\n","print(test_logits_T.shape)\n","print(Y_train_new.shape)\n","print(Y_test_new.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(5596, 2)\n","(1400, 2)\n","(5596, 4)\n","(1400, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2UEnZ3Ya0bko","outputId":"b6da1081-3867-4233-f149-c8b0da01141f"},"source":["# Prepare the student model that outputs probabilities with and without temperature\n","# Remove the softmax layer from the student network\n","temp = 10\n","customstudent.layers.pop()\n","\n","# Now collect the logits from the last layer\n","# This is going to be a tensor. And hence it needs to pass through a Activation layer\n","logits = customstudent.layers[-1].output \n","probs = layers.Activation('softmax')(logits)\n","\n","\n","# softed probabilities at raised temperature\n","logits_T = Lambda(lambda x: x / temp)(logits)\n","probs_T = layers.Activation('softmax')(logits_T)\n","\n","output = concatenate([probs, probs_T])\n","\n","# This is our new student model \n","customstudent = Model(customstudent.input, output)\n","\n","customstudent.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","conv2d_input (InputLayer)       [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 222, 222, 128 3584        conv2d_input[0][0]               \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 111, 111, 128 0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 109, 109, 64) 73792       max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 52, 52, 32)   18464       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 52, 52, 32)   0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 86528)        0           dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 2)            173058      flatten[0][0]                    \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 2)            0           dense_3[0][0]                    \n","__________________________________________________________________________________________________\n","lambda (Lambda)                 (None, 2)            0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 2)            0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 2)            0           lambda[0][0]                     \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 4)            0           activation_1[0][0]               \n","                                                                 activation_2[0][0]               \n","==================================================================================================\n","Total params: 268,898\n","Trainable params: 268,898\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"brOe8JSp0gA_"},"source":["# Declare knowledge distillation loss function\n","# This will be a teacher trained student model. \n","# This uses a knowledge distillation loss function\n","# Declare knowledge distillation loss\n","def knowledge_distillation_loss(y_true, y_pred, alpha):\n","\n","    # Extract the one-hot encoded values and the softs separately so that we can create two objective functions\n","    y_true, y_true_softs = y_true[: , :nb_classes], y_true[: , nb_classes:]\n","    \n","    y_pred, y_pred_softs = y_pred[: , :nb_classes], y_pred[: , nb_classes:]\n","    \n","    loss = alpha*logloss(y_true,y_pred) + (1-alpha)*logloss(y_true_softs, y_pred_softs)\n","    \n","    return loss\n","\n","# For testing use regular output probabilities - without temperature\n","def acc(y_true, y_pred):\n","    y_true = y_true[:, :nb_classes]\n","    y_pred = y_pred[:, :nb_classes]\n","    return categorical_accuracy(y_true, y_pred)\n","\n","customstudent.compile(\n","    #optimizer=optimizers.SGD(lr=1e-1, momentum=0.9, nesterov=True),\n","    optimizer='adadelta',\n","    loss=lambda y_true, y_pred: knowledge_distillation_loss(y_true, y_pred, 0.1),\n","    #loss='categorical_crossentropy',\n","    metrics=[acc] \n","  )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XLkOCYK0lBz","outputId":"e709ca8a-7801-41cc-a4b1-fac11b0af9de"},"source":["# Train the student model\n","epochs = 20\n","batch_size = 64\n","customstudent_student_his = customstudent.fit(x_train, Y_train_new,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_val, Y_test_new))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","88/88 [==============================] - 16s 184ms/step - loss: 0.0441 - acc: 0.8710 - val_loss: 0.0442 - val_acc: 0.8750\n","Epoch 2/20\n","88/88 [==============================] - 16s 184ms/step - loss: 0.0439 - acc: 0.8733 - val_loss: 0.0448 - val_acc: 0.8671\n","Epoch 3/20\n","88/88 [==============================] - 16s 185ms/step - loss: 0.0434 - acc: 0.8788 - val_loss: 0.0442 - val_acc: 0.8750\n","Epoch 4/20\n","88/88 [==============================] - 16s 185ms/step - loss: 0.0439 - acc: 0.8740 - val_loss: 0.0443 - val_acc: 0.8721\n","Epoch 5/20\n","88/88 [==============================] - 16s 185ms/step - loss: 0.0437 - acc: 0.8763 - val_loss: 0.0442 - val_acc: 0.8750\n","Epoch 6/20\n","88/88 [==============================] - 16s 186ms/step - loss: 0.0439 - acc: 0.8742 - val_loss: 0.0444 - val_acc: 0.8721\n","Epoch 7/20\n","88/88 [==============================] - 16s 186ms/step - loss: 0.0435 - acc: 0.8783 - val_loss: 0.0442 - val_acc: 0.8743\n","Epoch 8/20\n","88/88 [==============================] - 16s 186ms/step - loss: 0.0435 - acc: 0.8794 - val_loss: 0.0439 - val_acc: 0.8764\n","Epoch 9/20\n","88/88 [==============================] - 16s 187ms/step - loss: 0.0436 - acc: 0.8769 - val_loss: 0.0440 - val_acc: 0.8771\n","Epoch 10/20\n","88/88 [==============================] - 17s 188ms/step - loss: 0.0438 - acc: 0.8754 - val_loss: 0.0441 - val_acc: 0.8757\n","Epoch 11/20\n","88/88 [==============================] - 17s 188ms/step - loss: 0.0436 - acc: 0.8776 - val_loss: 0.0440 - val_acc: 0.8764\n","Epoch 12/20\n","88/88 [==============================] - 17s 188ms/step - loss: 0.0440 - acc: 0.8729 - val_loss: 0.0440 - val_acc: 0.8779\n","Epoch 13/20\n","88/88 [==============================] - 17s 188ms/step - loss: 0.0437 - acc: 0.8754 - val_loss: 0.0439 - val_acc: 0.8779\n","Epoch 14/20\n","88/88 [==============================] - 17s 188ms/step - loss: 0.0439 - acc: 0.8738 - val_loss: 0.0438 - val_acc: 0.8779\n","Epoch 15/20\n","88/88 [==============================] - 17s 189ms/step - loss: 0.0435 - acc: 0.8769 - val_loss: 0.0439 - val_acc: 0.8779\n","Epoch 16/20\n","88/88 [==============================] - 17s 189ms/step - loss: 0.0433 - acc: 0.8794 - val_loss: 0.0441 - val_acc: 0.8750\n","Epoch 17/20\n","88/88 [==============================] - 17s 189ms/step - loss: 0.0438 - acc: 0.8751 - val_loss: 0.0438 - val_acc: 0.8779\n","Epoch 18/20\n","88/88 [==============================] - 17s 189ms/step - loss: 0.0434 - acc: 0.8785 - val_loss: 0.0430 - val_acc: 0.8871\n","Epoch 19/20\n","88/88 [==============================] - 17s 189ms/step - loss: 0.0437 - acc: 0.8758 - val_loss: 0.0436 - val_acc: 0.8800\n","Epoch 20/20\n","88/88 [==============================] - 17s 189ms/step - loss: 0.0434 - acc: 0.8788 - val_loss: 0.0436 - val_acc: 0.8786\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eflf3u3938Pl","outputId":"2f12333c-a399-43e3-c525-06f0151e5e7c"},"source":["Y_val_pred_student = customstudent.predict(x_val)\n","print(f'The CustomStudent model Accuracy on the Validation Set:',accuracy_score(np.argmax(y_val, axis=1), np.argmax(Y_val_pred_student, axis=1)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The CustomStudent model Accuracy on the Validation Set: 0.8785714285714286\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4CmzFLB4Lew","outputId":"7dc80b1c-12a0-4c21-f3fe-73d991e79115"},"source":["#Now let's check my Y_test values\n","print(f'My Y_test values are:\\n' ,Y_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["My Y_test values are:\n"," [[1. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," ...\n"," [1. 0.]\n"," [0. 1.]\n"," [1. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZXiWzbBA4jgs","outputId":"681fc4c8-2342-4abe-92e5-0738cdba47fd"},"source":["#Now let's check my predcited values from X_test dataset\t\n","import timeit\n","\n","start = timeit.default_timer()\n","#Your statements here\n","y_pred_student = customstudent.predict(X_test)\n","print(f'My predicted Y_test values are:\\n' ,y_pred_student)\n","\n","stop = timeit.default_timer()\n","print('\\nTime: ',stop - start,'sec')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["My predicted Y_test values are:\n"," [[0.73105854 0.26894143 0.5249792  0.4750208 ]\n"," [0.26894143 0.73105854 0.4750208  0.5249792 ]\n"," [0.73105854 0.26894143 0.5249792  0.4750208 ]\n"," ...\n"," [0.73105854 0.2689415  0.5249792  0.47502083]\n"," [0.31061557 0.68938446 0.4800795  0.5199205 ]\n"," [0.73105854 0.26894143 0.5249792  0.4750208 ]]\n","\n","Time:  2.5788797919994977 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvQZH84Z4p9D","outputId":"42d7d3fe-d053-4cb6-c555-fdc58c702016"},"source":["start = timeit.default_timer()\n","#Your statements here\n","\n","#Now let's check the accuracy between the original & predicted (Y_test , y_pred)\n","print(f'My accuracy on Custom Student model on the Test set is:',accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_pred_student, axis=1)))\n","\n","stop = timeit.default_timer()\n","print('\\nTime: ',stop - start,'sec')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["My accuracy on Custom Student model on the Test set is: 0.9173333333333333\n","\n","Time:  0.0009702650004328461 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZQKmsH7ydM3","outputId":"7f734761-fa65-494c-8109-a2c44756ae65"},"source":["# Classification_report\n","print(f'Classification Report of Resnet50:\\n',classification_report(np.argmax(Y_test, axis=1), np.argmax(y_pred_student, axis=1)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Classification Report of Resnet50:\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.97      0.92      1500\n","           1       0.96      0.87      0.91      1500\n","\n","    accuracy                           0.92      3000\n","   macro avg       0.92      0.92      0.92      3000\n","weighted avg       0.92      0.92      0.92      3000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hKBaOwEJydE1"},"source":["# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n","\n","from sklearn.metrics import roc_curve, auc\n","from numpy import interp\n","from itertools import cycle\n","\n","num_of_classes = y_train.shape[1]\n","print(f'Auc Curve on Validation:\\n')\n","\n","\n","# Compute ROC curve and ROC area for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","for i in range(num_of_classes):\n","    fpr[i], tpr[i], _ = roc_curve(Y_test_new[:, i], Y_val_pred_student[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test_new.ravel(), Y_val_pred_student.ravel())\n","# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","\n","lw = 3\n","# Plot all ROC curves\n","\n","colors = cycle(['blue', 'orange', 'cornflowerblue'])\n","for i, color in zip(range(num_of_classes), colors):\n","    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n","             label='ROC curve of class {0} (area = {1:0.2f})'\n","             ''.format(i, roc_auc[i]))\n","    \n","plt.style.use('ggplot')\n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Some extension of Receiver operating characteristic to multi-class')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjoxO7sSyrJN"},"source":["# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n","\n","from sklearn.metrics import roc_curve, auc\n","from numpy import interp\n","from itertools import cycle\n","\n","num_of_classes = y_train.shape[1]\n","print(f'Auc Curve on Test set:\\n')\n","\n","\n","# Compute ROC curve and ROC area for each class\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","\n","for i in range(num_of_classes):\n","    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], y_pred_student[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), y_pred_student.ravel())\n","# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","\n","\n","lw = 3\n","# Plot all ROC curves\n","\n","colors = cycle(['blue', 'orange', 'cornflowerblue'])\n","for i, color in zip(range(num_of_classes), colors):\n","    plt.plot(fpr[i],tpr[i], color=color, lw=lw,\n","             label='ROC curve of class {0} (area = {1:0.2f})'\n","             ''.format(i, roc_auc[i]))\n","    \n","plt.style.use('ggplot')\n","plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Some extension of Receiver operating characteristic to multi-class')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vHcgXahESLKc"},"source":["-----"]}]}